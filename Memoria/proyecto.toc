\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\numberline {1}Introducción}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Resumen}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Estado del arte}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}Objetivos}{1}{section.1.3}%
\contentsline {chapter}{\numberline {2}Conceptos previos}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}Machine Learning}{3}{section.2.1}%
\contentsline {section}{\numberline {2.2}Componentes necesarios para el aprendizaje supervisado}{3}{section.2.2}%
\contentsline {section}{\numberline {2.3}División de datos en entrenamiento y test}{4}{section.2.3}%
\contentsline {section}{\numberline {2.4}Tipos de aprendizaje}{4}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Aprendizaje Supervisado}{4}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Aprendizaje No Supervisado}{4}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Aprendizaje Por Refuerzo}{4}{subsection.2.4.3}%
\contentsline {section}{\numberline {2.5}Redes Neuronales Totalmente Conectadas}{5}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Neurona}{5}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Estructura por capas}{5}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}Funciones de activación}{6}{subsection.2.5.3}%
\contentsline {subsubsection}{ReLU}{6}{section*.8}%
\contentsline {subsubsection}{Sigmoide}{6}{section*.9}%
\contentsline {subsubsection}{SoftMax}{7}{section*.10}%
\contentsline {subsection}{\numberline {2.5.4}One-hot encoding}{8}{subsection.2.5.4}%
\contentsline {subsection}{\numberline {2.5.5}Función de error o pérdida}{8}{subsection.2.5.5}%
\contentsline {subsubsection}{Entropía Cruzada}{8}{section*.11}%
\contentsline {subsubsection}{Sigmoid Cross Entropy Loss}{8}{section*.12}%
\contentsline {subsection}{\numberline {2.5.6}Descenso del gradiente}{8}{subsection.2.5.6}%
\contentsline {subsubsection}{Entrenamiento}{9}{section*.13}%
\contentsline {subsection}{\numberline {2.5.7}Tipos de codificaciones}{9}{subsection.2.5.7}%
\contentsline {section}{\numberline {2.6}Redes Neuronales Convolucionales}{10}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Tipos de capas}{10}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}Estructura por capas}{10}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}ForwardPropagation}{10}{subsection.2.6.3}%
\contentsline {chapter}{\numberline {3}Aportaciones}{11}{chapter.3}%
\contentsline {section}{\numberline {3.1}Redes Neuronales Totalmente Conectadas}{11}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}BackPropagation con 1 capa oculta}{11}{subsection.3.1.1}%
\contentsline {subsubsection}{Capa output}{12}{section*.14}%
\contentsline {subsubsection}{Función activación de la capa output}{13}{section*.15}%
\contentsline {subsubsection}{Pesos capas h1-output}{14}{section*.16}%
\contentsline {subsubsection}{Capa oculta h1}{14}{section*.17}%
\contentsline {subsubsection}{Pesos capas input-h1}{15}{section*.18}%
\contentsline {subsubsection}{Capa input}{16}{section*.19}%
\contentsline {chapter}{\numberline {4}Adaptación GPU}{17}{chapter.4}%
\contentsline {section}{\numberline {4.1}GPU en Redes Neuronales Totalmente Conectadas}{17}{section.4.1}%
\contentsline {section}{\numberline {4.2}GPU en Redes Neuronales Convolucionales}{17}{section.4.2}%
\contentsline {chapter}{\numberline {5}Comparación con distintas plataformas}{19}{chapter.5}%
\contentsline {section}{\numberline {5.1}cuDNN}{19}{section.5.1}%
