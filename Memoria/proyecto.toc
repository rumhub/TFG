\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\numberline {1}Introducción}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Resumen}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Objetivos}{2}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Objetivos de aprendizaje}{2}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Objetivos de diseño y desarrollo}{3}{subsection.1.2.2}%
\contentsline {chapter}{\numberline {2}Conceptos previos}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Machine Learning}{5}{section.2.1}%
\contentsline {section}{\numberline {2.2}Componentes necesarios para el aprendizaje supervisado}{5}{section.2.2}%
\contentsline {section}{\numberline {2.3}División de datos en entrenamiento y test}{6}{section.2.3}%
\contentsline {section}{\numberline {2.4}Tipos de aprendizaje}{6}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Aprendizaje Supervisado}{6}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Aprendizaje No Supervisado}{6}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Aprendizaje Por Refuerzo}{6}{subsection.2.4.3}%
\contentsline {section}{\numberline {2.5}Redes Neuronales Totalmente Conectadas}{7}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Neurona}{7}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Estructura por capas}{7}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}Funciones de activación}{8}{subsection.2.5.3}%
\contentsline {subsubsection}{ReLU}{8}{section*.10}%
\contentsline {subsubsection}{Sigmoide}{8}{section*.12}%
\contentsline {subsection}{\numberline {2.5.4}Capa SoftMax}{9}{subsection.2.5.4}%
\contentsline {subsection}{\numberline {2.5.5}Función de error o pérdida}{10}{subsection.2.5.5}%
\contentsline {subsubsection}{Entropía Cruzada}{10}{section*.15}%
\contentsline {subsection}{\numberline {2.5.6}Descenso del gradiente}{10}{subsection.2.5.6}%
\contentsline {subsubsection}{Entrenamiento}{11}{section*.17}%
\contentsline {subsubsection}{Descenso del gradiente estocástico}{11}{section*.18}%
\contentsline {subsection}{\numberline {2.5.7}Inicialización de pesos y sesgos}{12}{subsection.2.5.7}%
\contentsline {subsubsection}{Inicialización de pesos}{12}{section*.19}%
\contentsline {subsubsection}{Inicialización de sesgos}{12}{section*.20}%
\contentsline {subsection}{\numberline {2.5.8}Tipos de codificaciones}{12}{subsection.2.5.8}%
\contentsline {subsection}{\numberline {2.5.9}Propagación hacia delante con softmax}{12}{subsection.2.5.9}%
\contentsline {section}{\numberline {2.6}Redes Neuronales Convolucionales}{13}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Introducción a CNNs}{13}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}Capa convolucional}{13}{subsection.2.6.2}%
\contentsline {subsubsection}{Componentes}{13}{section*.21}%
\contentsline {subsubsection}{Propagación hacia delante}{14}{section*.23}%
\contentsline {subsubsection}{Propagación hacia delante, canales de profundidad}{15}{section*.25}%
\contentsline {subsubsection}{Propagación hacia delante, número de filtros}{16}{section*.27}%
\contentsline {subsubsection}{Relleno o ``Padding''}{16}{section*.29}%
\contentsline {subsubsection}{Relleno completo}{17}{section*.31}%
\contentsline {subsection}{\numberline {2.6.3}Capa de agrupación máxima}{19}{subsection.2.6.3}%
\contentsline {subsubsection}{Componentes}{19}{section*.34}%
\contentsline {subsubsection}{Propagación hacia delante}{19}{section*.36}%
\contentsline {subsubsection}{Propagación hacia delante, canales de profundidad}{20}{section*.38}%
\contentsline {subsubsection}{Propagación hacia detrás}{20}{section*.40}%
\contentsline {subsection}{\numberline {2.6.4}Capa de aplanado}{22}{subsection.2.6.4}%
\contentsline {subsubsection}{Propagación hacia delante}{22}{section*.42}%
\contentsline {subsubsection}{Propagación hacia detrás}{23}{section*.44}%
\contentsline {section}{\numberline {2.7}cuDNN (Deep Neural Network)}{23}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Manejador}{24}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Tensores}{24}{subsection.2.7.2}%
\contentsline {subsubsection}{Tensor 3D}{24}{section*.46}%
\contentsline {subsubsection}{Tensor 4D}{24}{section*.47}%
\contentsline {chapter}{\numberline {3}Aportaciones}{25}{chapter.3}%
\contentsline {section}{\numberline {3.1}Redes Neuronales Totalmente Conectadas}{25}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Gradiente de la función de pérdida respecto a SoftMax, \cite {Cross_entropy_backprop} \cite {Cross_entropy_backprop_grad_input}}{25}{subsection.3.1.1}%
\contentsline {subsubsection}{Gradiente de la función de error}{25}{section*.49}%
\contentsline {subsubsection}{Derivada de softmax respecto de su entrada, $\frac {\partial O_i}{\partial Z_k}$}{26}{section*.50}%
\contentsline {subsubsection}{Caso $\frac {S(Z_i)}{Z_i}$}{26}{section*.51}%
\contentsline {subsubsection}{Caso $\frac {S(Z_i)}{Z_j}$, con i $\neq $ j}{27}{section*.52}%
\contentsline {subsubsection}{Combinación de casos}{27}{section*.53}%
\contentsline {subsubsection}{Simplificación One-Hot}{28}{section*.54}%
\contentsline {subsection}{\numberline {3.1.2}BackPropagation con 1 capa oculta \cite {NN_backpropagation} \cite {NN_backprop_2} }{28}{subsection.3.1.2}%
\contentsline {subsubsection}{Capa SoftMax}{29}{section*.56}%
\contentsline {subsubsection}{Pesos capas h1-SoftMax}{29}{section*.58}%
\contentsline {subsubsection}{Sesgos capa softmax}{30}{section*.60}%
\contentsline {subsubsection}{Capa oculta h1}{30}{section*.61}%
\contentsline {subsubsection}{Pesos capas input-h1}{32}{section*.64}%
\contentsline {subsubsection}{Sesgos capa h1}{32}{section*.66}%
\contentsline {subsubsection}{Capa input}{33}{section*.67}%
\contentsline {subsection}{\numberline {3.1.3}Retropropagación con 2 capas ocultas}{34}{subsection.3.1.3}%
\contentsline {subsubsection}{Capa SoftMax}{34}{section*.71}%
\contentsline {subsubsection}{Pesos capas h2-SoftMax}{35}{section*.73}%
\contentsline {subsubsection}{Sesgos capa softmax}{35}{section*.75}%
\contentsline {subsubsection}{Capa oculta h2}{36}{section*.76}%
\contentsline {subsubsection}{Pesos capas h1-h2}{37}{section*.79}%
\contentsline {subsubsection}{Sesgos capa h2}{38}{section*.81}%
\contentsline {subsubsection}{Capa oculta h1}{38}{section*.82}%
\contentsline {subsubsection}{Pesos capa input-h1}{39}{section*.85}%
\contentsline {subsubsection}{Sesgos capa h1}{40}{section*.87}%
\contentsline {subsubsection}{Capa input}{40}{section*.88}%
\contentsline {subsection}{\numberline {3.1.4}Conclusiones}{41}{subsection.3.1.4}%
\contentsline {subsubsection}{Gradiente respecto a la entrada}{42}{section*.91}%
\contentsline {subsubsection}{Gradiente respecto a los pesos}{42}{section*.93}%
\contentsline {subsubsection}{Gradiente respecto a sesgos}{43}{section*.95}%
\contentsline {section}{\numberline {3.2}Paralelización en entrenamiento}{43}{section.3.2}%
\contentsline {subsubsection}{Tipos de paralelismo}{43}{section*.96}%
\contentsline {subsubsection}{Paralelismo en SGD}{44}{section*.97}%
\contentsline {section}{\numberline {3.3}Redes Neuronales Convolucionales}{45}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Propagación hacia detrás}{45}{subsection.3.3.1}%
\contentsline {subsubsection}{Sumatoria de gradientes}{45}{section*.99}%
\contentsline {subsubsection}{Gradiente de $Y^c_{11}$}{45}{section*.100}%
\contentsline {subsubsection}{Gradiente de $Y^c_{12}$}{46}{section*.101}%
\contentsline {subsubsection}{Gradiente de $Y^c_{21}$}{47}{section*.103}%
\contentsline {subsubsection}{Gradiente de $Y^c_{22}$}{48}{section*.105}%
\contentsline {subsubsection}{Gradiente respecto a pesos como convolución}{49}{section*.107}%
\contentsline {subsubsection}{Gradiente respecto a entrada como convolución}{50}{section*.109}%
\contentsline {subsection}{\numberline {3.3.2}Propagación hacia detrás con relleno}{53}{subsection.3.3.2}%
\contentsline {subsubsection}{Gradiente de $Y^c_{11}$}{53}{section*.113}%
\contentsline {subsubsection}{Gradiente de $Y^c_{12}$}{54}{section*.115}%
\contentsline {subsubsection}{Gradiente de $Y^c_{13}$}{55}{section*.117}%
\contentsline {subsubsection}{Gradiente de $Y^c_{21}$}{55}{section*.119}%
\contentsline {subsubsection}{Gradiente de $Y^c_{22}$}{56}{section*.121}%
\contentsline {subsubsection}{Gradiente de $Y^c_{23}$}{57}{section*.123}%
\contentsline {subsubsection}{Gradiente de $Y^c_{31}$}{58}{section*.125}%
\contentsline {subsubsection}{Gradiente de $Y^c_{32}$}{58}{section*.127}%
\contentsline {subsubsection}{Gradiente de $Y^c_{33}$}{59}{section*.129}%
\contentsline {subsubsection}{Gradiente respecto a pesos como convolución}{60}{section*.131}%
\contentsline {subsubsection}{Gradiente respecto a entrada como convolución}{61}{section*.133}%
\contentsline {chapter}{\numberline {4}Adaptación GPU}{63}{chapter.4}%
\contentsline {section}{\numberline {4.1}Convolución como GEMM }{64}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Memoria requerida al emplear GEMM}{65}{subsection.4.1.1}%
\contentsline {section}{\numberline {4.2}Retropropagación GEMM en capa convolucional}{66}{section.4.2}%
\contentsline {section}{\numberline {4.3}Capa totalmente conectada como GEMM \cite {nvidia_back_fully_GEMM}}{69}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Propagación hacia delante}{69}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Retropropagación}{70}{subsection.4.3.2}%
\contentsline {subsubsection}{Gradiente respecto a la entrada}{70}{section*.141}%
\contentsline {subsubsection}{Gradiente respecto a los pesos}{71}{section*.144}%
\contentsline {section}{\numberline {4.4}CUDA}{72}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Multiplicación de matrices en CUDA}{72}{subsection.4.4.1}%
\contentsline {chapter}{\numberline {5}Comparación con distintas plataformas}{75}{chapter.5}%
\contentsline {section}{\numberline {5.1}cuDNN}{75}{section.5.1}%
