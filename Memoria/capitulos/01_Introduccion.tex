\chapter{Introducción}

\section{Resumen}
En los inicios, las computadoras empleaban exclusivamente CPUs para llevar a cabo tareas de programación generales. Sin embargo, desde la última década empezaron a surgir otros elementos de procesamiento como las GPUs, las cuales se desarrollaron inicialmente para realizar cálculos gráficos paralelos especializados. Con el tiempo, han ido evolucionando tanto en prestaciones como en versatilidad, permitiendo a día de hoy su uso en tareas de cómputo paralelo de propósito general de alto rendimiento. \\
Gracias a ello se logró el cambio de sistemas homogéneos a heterogéneos, el cual destaca por ser un logro de gran importancia y considerable magnitud en toda la historia de la computación de alto rendimiento. \\
La computación homogénea emplea uno o más procesadores de la misma arquitectura para ejecutar una aplicación. Por otro lado, la computación heterogénea no se rige por esas reglas y rompe dicha limitación, empleando con ello un conjunto de arquitecturas distintas para ejecutar una misma aplicación, de tal forma que cada arquitectura se encargue de aquellas tareas para las que se encuentra mejor preparada, obteniendo por ello una mejora notable en cuanto a rendimiento. \\
En el campo de computación heterogénea destaca el caso de CPU y GPU, pues su conjunto forma una excelente complementación. Mientras que la CPU se encuentra optimizada para tareas dinámicas de ráfagas de cómputo cortas y un flujo de control impredecible, la GPU se especializa justamente en el caso contrario: ráfagas de cómputo altamente demandantes pero con un flujo de control simple. \\
De esta forma, si una tarea presenta un número reducido de datos, una lógica de control sofisticada y un bajo nivel de paralelismo, se asignará a la CPU. Si por el contrario esta presenta una cantidad exuberante de datos, así como un alto grado de paralelismo en ellos, se asignará a la GPU pues presenta un gran número de núcleos y puede dar soporte a una cantidad de hebras mucho mayor que la posible mediante CPU. \cite{Professional_CUDA_C} \\
Tal y como se explicará en detalle en secciones posteriores, el patrón de entrenamiento en redes neuronales convolucionales es computacionalmente intensivo y altamente paralelo \cite{Programming_Massively}. Por ello, se adoptará un enfoque de computación heterogénea, con el propósito de acortar los tiempos de ejecución requeridos en dichos entrenamientos. \\
Con el objetivo de lograr una mayor comprensión sobre sistemas heterogéneos aplicados a redes neuronales convolucionales (CNNs), a lo largo de este proyecto se desarrollarán una serie de implementaciones. Primero se empezará por una implementación secuencial que simplemente use la CPU. Después, se creará otra implementación que emplee paralelismo a nivel de CPU mediante la librería OpenMP. Una vez adquiridos conocimientos sobre CNNs y unas bases paralelismo a nivel de CPU, tendrá lugar la creación de una tercera implementación, caracterizada por ser el primer sistema heterogéneo de este proyecto y emplear CUDA. Por último, una vez entendidas las bases de CNNs, paralelismo tanto a nivel de CPU como a nivel de GPU, y sistemas heterogéneos aplicados a CNNs, se contarán con los conocimientos necesarios para crear y entender como funcionan realmente por debajo las librerías del sector. Por ello, se seleccionó una librería de bajo nivel y grandes prestaciones como cuDNN para elaborar una última implementación y lograr obtener un mayor rendimiento, a la vez que consolidar lo aprendido durante todo el proceso. \\
Cabe destacar que cada una de las implementaciones a desarrollar serán de muy bajo nivel y no se apoyarán en ninguna librería externa que facilite los cálculos, a excepción exclusiva de OpenMP, CUDA y cuDNN, tal y como se comentó anteriormente. 


\section{Objetivos}

El principal objetivo de este proyecto es diseñar y desarrollar redes neuronales convolucionales (CNNs) desde sus cimientos, a un nivel de programación muy bajo. Esto permite una profunda comprensión de sus fundamentos y funcionamiento, comunes a bibliotecas especializadas en el campo. Para ello, se desarrollan distintas implementaciones sobre el mismo software, cada una con mejores prestaciones que la anterior. \\
La principal razón de este proyecto es aprender los fundamentos del machine learning aplicados a redes neuronales convolucionales, así como el diseño y desarrollo de sistemas heterogéneos de altas prestaciones, y el uso de librerías de bajo nivel del ámbito como cudnn, que a su vez es empleada por otras librerías de más alto nivel del sector. \\
A continuación se desglosan en dos categorías los objetivos específicos que permiten alcanzar el objetivo principal. Los objetivos de aprendizaje se centran en la adquisición de los conocimientos teóricos requeridos para la concepción de este proyecto, mientras que los objetivos de diseño y desarrollo buscan llevar a la práctica dicho conocimiento teórico adquirido anteriormente, aportando con ello una experiencia de aprendizaje de mayor categoría.

\subsection{Objetivos de aprendizaje}

\begin{enumerate}[label=\textbullet]
	\item \textbf{OA.1} Estudiar los fundamentos del machine learning y como se aplican a CNNs.
	
	\item \textbf{OA.2} Estudiar los distintos componentes de una CNN y la conexión entre los mismos.
	
	\item \textbf{OA.3} Estudiar implementaciones similares a las planteadas en este proyecto para comprender y analizar las funcionalidades y propiedades que se requieren. 
	
	\item \textbf{OA.4} Estudiar como diseñar e implementar CNNs empleando tecnologías de programación de bajo nivel como C++.
	
	\item \textbf{OA.5} Estudiar como diseñar e implementar CNNs empleando paralelización a nivel de CPU mediante OpenMP y C++.
	
	\item \textbf{OA.6} Estudiar como diseñar e implementar sistemas heterogéneos empleando CUDA.

	\item \textbf{OA.7} Estudiar como diseñar e implementar CNNs mediante sistemas heterogéneos.

	\item \textbf{OA.8} Estudiar como diseñar e implementar CNNs mediante librerías de bajo nivel como cuDNN.

\end{enumerate}

\subsection{Objetivos de diseño y desarrollo}

\begin{enumerate}[label=\textbullet]
	\item \textbf{ODD.1} Diseñar e implementar CNNs a bajo nivel mediante C++.
	
	\item \textbf{ODD.2} Diseñar e implementar CNNs a bajo nivel mediante C++ y paralelización a nivel de CPU mediante OpenMP.

	\item \textbf{ODD.3} Diseñar e implementar CNNs a bajo nivel como sistema heterogéneo mediante C++ y CUDA.

	\item \textbf{ODD.4} Diseñar e implementar CNNs mediante la librería de bajo nivel cuDNN.		
	
\end{enumerate}
