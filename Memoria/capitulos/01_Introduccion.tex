\chapter{Introducción}

Este capítulo establece el marco general del proyecto. Comienza con un resumen que ofrece una visión general del contexto, propósito y relevancia del trabajo. A continuación, se presentan los objetivos del proyecto, divididos en objetivos de aprendizaje, enfocados en la adquisición de conocimientos teóricos, y objetivos de diseño e implementación, que buscan aplicar estos conocimientos en la práctica. El capítulo, también incluye una sección de planificación, donde se detalla la estructura temporal del proyecto, y finaliza con una estimación de costos, donde se analizan los recursos financieros y materiales requeridos para su ejecución.

\section{Resumen}
En los inicios, las computadoras empleaban exclusivamente CPUs (Central Processing Units) \cite{CPU_definicion} para llevar a cabo tareas de programación de propósito general. Sin embargo, desde la última década empezaron a surgir otros elementos de procesamiento como las GPUs (Graphics Processing Units) \cite{GPU_definicion}, las cuales se desarrollaron inicialmente para realizar cálculos gráficos paralelos necesarios para el proceso de generación de imágenes o vídeos digitales. Con el tiempo, Las GPUs han ido evolucionando tanto en prestaciones como en versatilidad, permitiendo a día de hoy su uso en tareas de cómputo paralelo de propósito general de alto rendimiento. \\
Gracias a la difusión de las GPUs en aplicaciones de propósito general, se logró el cambio de sistemas homogéneos a heterogéneos \cite{sitemas_heterogeneo_definicion}, el cual destaca por ser un logro de gran importancia y considerable magnitud en toda la historia de la computación de alto rendimiento. \\
La computación homogénea emplea uno o más procesadores de la misma arquitectura para ejecutar una aplicación. Por otro lado, la computación heterogénea no se rige por esas reglas y rompe dicha limitación, empleando con ello un conjunto de arquitecturas distintas para ejecutar una misma aplicación, de tal forma que cada arquitectura se encargue de aquellas tareas para las que se encuentra mejor preparada, obteniendo por ello una mejora notable en cuanto a rendimiento. \\
En el campo de la computación heterogénea destaca el uso agrupado de CPUs y GPUs, pues su conjunto forma una excelente complementación. Mientras que la CPU se encuentra optimizada para tareas dinámicas de ráfagas de cómputo cortas y un flujo de control impredecible, la GPU se especializa justamente en el caso contrario: ráfagas de cómputo muy costosas pero con un flujo de control simple. \\
De esta forma, si una tarea presenta un número reducido de datos, una lógica de control sofisticada y un bajo nivel de paralelismo, se asignará a la CPU. Si por el contrario, esta presenta una cantidad exuberante de datos, así como un alto grado de paralelismo al procesar dichos datos, se asignará a la GPU pues presenta un gran número de núcleos y puede dar soporte a una cantidad de hebras mucho mayor que la posible mediante CPU. \cite{Professional_CUDA_C} \\
Tal y como se explicará en detalle en secciones posteriores, el patrón de entrenamiento en redes neuronales convolucionales o CNNs (Convolutional Neural Neworks) \cite{CNN_definicion} es computacionalmente intensivo y altamente paralelo \cite{Programming_Massively}. Por ello, se adoptará un enfoque de computación heterogénea en este ámbito, con el propósito de acortar los tiempos de ejecución requeridos en dichos entrenamientos. Las redes neuronales convolucionales son de gran importancia y destacan por ser un subconjunto del aprendizaje automático \cite{Aprendizaje_automatico_definicion} y el corazón de los algoritmos de aprendizaje profundo \cite{Deep_learning_definicion}, además de potenciar las tareas de reconocimiento de imágenes \cite{image_recognition_CNN} y visión artificial \cite{computer_vision_definicion}. Entre sus principales usos destacan la detección de objetos en imágenes o vídeos \cite{object_detection_CNN}, segmentación de imágenes \cite{image_segmentation_CNN} , generación de imágenes \cite{generative_CNN}, análisis de vídeos \cite{video_analytics_CNN}, procesamiento del lenguaje natural \cite{NLP_CNN}, o incluso sistemas autónomos \cite{sitemas_autonomos_CNN}, entre otros. \\
Con el objetivo de lograr una mayor comprensión sobre sistemas heterogéneos aplicados a redes neuronales convolucionales, a lo largo de este proyecto se desarrollarán una serie de implementaciones. Primero se empezará por una implementación secuencial que aproveche un solo core de la CPU usando una sola hebra. Después, se creará otra implementación que aproveche el paralelismo a nivel de grano grueso en CPU mediante la API OpenMP \cite{openmp_forum}. Una vez adquiridos conocimientos sobre redes neuronales convolucionales y unas bases paralelismo a nivel de CPU, tendrá lugar la creación de una tercera implementación, caracterizada por ser el primer sistema heterogéneo de este proyecto y emplear el framework CUDA \cite{cuda_forum}. Por último, una vez entendidas las bases de CNNs, paralelismo tanto a nivel de CPU como a nivel de GPU, y sistemas heterogéneos aplicados a CNNs, se contarán con los conocimientos necesarios para crear y entender cómo funcionan realmente por debajo las librerías del sector. Por ello, se seleccionó una librería de bajo nivel altamente optimizada como cuDNN \cite{cuDNN} para elaborar una última implementación y lograr obtener un mayor rendimiento, a la vez que se consolida lo aprendido durante todo el proceso. \\
Cabe destacar que cada una de las implementaciones a desarrollar serán de muy bajo nivel y no se apoyarán en ninguna librería o framework externo que facilite los cálculos, con la única excepción de OpenMP, CUDA y cuDNN, tal y como se comentó anteriormente. 


\section{Objetivos}

El principal objetivo de este proyecto es diseñar y desarrollar redes neuronales convolucionales (CNNs) desde sus cimientos, a un nivel de programación relativamente bajo. Esto permite una profunda comprensión de sus fundamentos y funcionamiento, comunes a bibliotecas especializadas en el campo. Para ello, se desarrollan distintas implementaciones de la misma aplicación, cada una con mejores prestaciones que la anterior. \\
La principal razón de este proyecto es aprender los fundamentos del machine learning aplicados a redes neuronales convolucionales, así como el diseño y desarrollo de sistemas heterogéneos de altas prestaciones, y el uso de librerías de bajo nivel del ámbito como cuDNN, que a su vez es empleada por otras librerías de más alto nivel del sector como Caffe2 \cite{Caffe2}, Keras \cite{Keras}, MATLAB \cite{Matlab}, Pytorch \cite{Pytorch}, o TensorFlow \cite{Tensorflow}, entre otras \cite{cuDNN_librerias}. \\
A continuación se desglosan en dos categorías los objetivos específicos que permiten alcanzar el objetivo principal. Los objetivos de aprendizaje se centran en la adquisición de los conocimientos teóricos requeridos para el desarrollo de este proyecto, mientras que los objetivos de diseño e implementación buscan llevar a la práctica dicho conocimiento teórico adquirido anteriormente, aportando con ello una experiencia de aprendizaje de mayor categoría.

\subsection{Objetivos de aprendizaje}

\begin{enumerate}[label=\textbullet]
	\item \textbf{OA.1} Conocer los fundamentos del machine learning y cómo se aplican a CNNs.
	
	\item \textbf{OA.2} Conocer los distintos componentes de una CNN y la conexión entre los mismos.
	
	\item \textbf{OA.3} Comprender implementaciones similares a las planteadas en este proyecto para comprender y analizar las funcionalidades y propiedades que se requieren. 
	
	\item \textbf{OA.4} Aprender cómo diseñar e implementar CNNs empleando tecnologías de programación de bajo nivel como C++.
	
	\item \textbf{OA.5} Comprender el diseño e implementación de CNNs empleando paralelización a nivel de CPU mediante OpenMP y C++.
	
	\item \textbf{OA.6} Mejorar mi aprendizaje sobre diseño e implementación de sistemas heterogéneos usando CUDA.

	\item \textbf{OA.7} Comprender el diseño e implementación de CNNs mediante sistemas heterogéneos usando CUDA.

	\item \textbf{OA.8} Aprender cómo diseñar e implementar CNNs mediante librerías específicas para este ámbito y de bajo nivel como cuDNN.

\end{enumerate}

\subsection{Objetivos de diseño e implementación}

\begin{enumerate}[label=\textbullet]
	\item \textbf{ODD.1} Diseñar e implementar CNNs a bajo nivel mediante C++.
	
	\item \textbf{ODD.2} Diseñar e implementar CNNs a bajo nivel mediante C++ y paralelización a nivel de CPU mediante OpenMP.

	\item \textbf{ODD.3} Diseñar e implementar CNNs a bajo nivel como sistema heterogéneo mediante C++ y CUDA.

	\item \textbf{ODD.4} Diseñar e implementar CNNs mediante la librería de bajo nivel cuDNN.		
	
\end{enumerate}

\section{Planificación}

Para el desarrollo de este proyecto, se requiere llevar a cabo una serie de tareas con diferentes dificultades e importancias. A continuación, se muestra una planificación general del mismo en la tabla \ref{tabla_planificación}, junto con las fases que componen su desarrollo, y una planificación temporal de cada apartado por separado,  (para obtener información adicional, véase el apéndice \ref{planificacion}). Cabe destacar que cada apartado se basa en los conocimientos adquiridos en los apartados anteriores, a la vez que introduce conceptos nuevos y mejora las prestaciones del modelo. De esta manera, cada apartado supondrá retos nuevos nunca antes vistos y, si un apartado anterior presenta algún fallo desconocido en el momento de su desarrollo, se deberá volver a la etapa anterior y subsanarlo. Tras solventarlo, se podrá proseguir con la etapa posterior. Además, dada la naturaleza de `caja negra' de las redes neuronales, estas presentan cierta dificultad a la hora de depurar el código. Por tanto, esto supondrá un tiempo de depuración considerable en todas y cada una de las implementaciones, tal y como se mostrará a continuación.

\begin{enumerate}[label=\textbullet]
	\item \textbf{Estudio previo}: Consiste en el estudio y comprensión de cuestiones generales, dentro del campo del aprendizaje automático y visión por computador, comunes a redes neuronales totalmente conectadas, y redes neuronales convolucionales.
	
	\item \textbf{Investigación y desarrollo de redes neuronales totalmente conectadas}: En este periodo, se aborda la investigación y comprensión sobre las redes neuronales totalmente conectadas a bajo nivel. De esta manera, sabía que podría generar cualquier tipo de red totalmente conectada de manera dinámica, sin necesidad de realizar ningún tipo de cálculo posterior, independientemente del lenguaje de programación empleado, así como del uso o no de librerías que faciliten el proceso. 
	
	\item \textbf{Investigación y desarrollo de redes neuronales convolucionales}:
	Una vez familiarizado con redes neuronales totalmente conectadas, se trabaja la comprensión de las redes neuronales convolucionales, pues se encuentran ampliamente relacionadas.
	\item \textbf{Investigación y desarrollo de sistemas homogéneos con OpenMP}:
	
	Una vez comprendido el funcionamiento tanto, de las redes neuronales totalmente conectadas, como de las redes neuronales convolucionales, me centré en reducir los tiempos de cómputo requeridos en su entrenamiento, mediante un paralelismo orientado a datos con OpenMP, (se analizará en detalle en secciones posteriores).
	
	\item \textbf{Investigación y desarrollo de sistemas heterogéneos con CUDA y cuDNN}:
	Con el conocimiento teórico y práctico ya adquirido sobre sistemas homogéneos, aplicados tanto a redes neuronales totalmente conectadas como a redes neuronales convolucionales, se avanza ahora hacia la exploración de sistemas heterogéneos, aplicados a estas mismas arquitecturas de redes neuronales.
\end{enumerate}


\begin{table}[H]
	\centering
	\begin{tabular}{|lll|}
		\hline
		Apartado 	 &\vline  & Tiempo (Horas) \\
		\hline
		
		Estudio previo    & \vline & 16 \\			
		\hline
		Investigación y desarrollo  	 & \vline & 	\\
		de redes neuronales  	 & \vline & 143	\\
		totalmente conectadas 	 & \vline & 	\\
		\hline
		Investigación y desarrollo    & \vline & 	 \\	
		de redes neuronales    & \vline & 152	 \\			
		convolucionales    & \vline & 	 \\					
		\hline
		Investigación y desarrollo  	 & \vline & 	 \\
		de sistemas homogéneos  	 & \vline & 103	 \\
		con OpenMP 	 & \vline & 	 \\
		\hline
		Investigación y desarrollo     & \vline &  	\\
		de sistemas heterogéneos    & \vline &  \\ 
		con CUDA y cuDNN    & \vline & 282 \\ 	
		\hline
		\hline
		Tiempo total:				& \vline & 696 \\
		\hline
	\end{tabular}
	\caption{Planificación del proyecto}
	\label{tabla_planificación}
\end{table}

\section{Estimación de costos}

Para la correcta ejecución del proyecto descrito, se ha desarrollado un plan de costos que contempla los recursos humanos, materiales y tecnológicos necesarios para completar las actividades descritas en la planificación. El presente plan se divide en las siguientes categorías: costos de personal, costos de equipos y software, y otros costos indirectos.

\subsection{Costos de personal}

El costo asociado al personal abarca las horas invertidas en cada una de las actividades planificadas en el proyecto. Para el cálculo de estos costos, se ha utilizado un valor promedio de 22€ por hora de trabajo.

\begin{table}[H]
	\centering
	\begin{tabular}{|lll|}
		\hline
		Apartado 	 &\vline  & Costos (€) \\
		\hline
		
		Estudio previo    & \vline & 352 \\			
		\hline
		Investigación y desarrollo  	 & \vline & 	\\
		de redes neuronales  	 & \vline & 3146	\\
		totalmente conectadas 	 & \vline & 	\\
		\hline
		Investigación y desarrollo    & \vline & 	 \\	
		de redes neuronales    & \vline & 3344	 \\			
		convolucionales    & \vline & 	 \\					
		\hline
		Investigación y desarrollo  	 & \vline & 	 \\
		de sistemas homogéneos  	 & \vline & 2266	 \\
		con OpenMP 	 & \vline & 	 \\
		\hline
		Investigación y desarrollo     & \vline &  	\\
		de sistemas heterogéneos    & \vline &  \\ 
		con CUDA y cuDNN    & \vline & 6204 \\ 	
		\hline
		\hline
		Costos de personal total:				& \vline & 15312 \\
		\hline
	\end{tabular}
	\caption{Costes del proyecto}
	\label{tabla_costes}
\end{table}

En el Cuadro \ref{tabla_costes}, se presentan los costos de personal correspondientes a cada sección del proyecto.

\subsection{Costos de equipo}

Para las implementaciones homogéneas que utilizan exclusivamente CPU, una instacia AWS comparable al equipo usado para el desarrollo de este proyecto, sería la instancia c6i.2xlarge, con un precio aproximado de 0,33€ por hora. Se estima que el costo total para el uso de esta instancia es de aproximadamente unos 92€.

En el caso de entornos heterogéneos que requieren GPU, se contempla el uso de una Nvidia Tesla T4, con un costo aproximado de 0,60 €/hora. Se estima un costo total de 138€ para su utilización en el proyecto.

\subsection{Resumen total de costos}

Considerando los costos previamente detallados, el Cuadro \ref{tabla_costes_total} proporciona un resumen integral de los costos totales asociados al proyecto. Este cuadro, integra tanto los costos de personal, como los costos derivados del uso de recursos computacionales, permitiendo una visión consolidada de la inversión total requerida. En el cuadro, se desglosan los gastos por categorías, facilitando así una evaluación clara y precisa del presupuesto del proyecto.

\begin{table}[H]
	\centering
	\begin{tabular}{|lll|}
		\hline
		Apartado 	 &\vline  & Costos (€) \\
		\hline
		
		Costos de personal    & \vline & 15312 \\			
		\hline
		Costos de equipo  	 & \vline & 230	\\

		\hline
		\hline
		Costos totales:				& \vline & 15542 \\
		\hline
	\end{tabular}
	\caption{Costes totales del proyecto}
	\label{tabla_costes_total}
\end{table}

