@book{Programming_Massively,
	title     = "Programming Massively Parallel Processors",
	author    = "Wen-emi W.Hwu, David B.kirk, Izzat El Hajj",
	publisher = "Morgan Kaufmann",
	address = "50 Hampshire Street, 5th Floor, Cambridge, MA 02139, United States",
	edition = "4",
	year      = "2022",
}

@book{Professional_CUDA_C,
	title     = "Professional Cuda C Programming",
	author    = "John Cheng, Max Grossman, Ty McKercher",
	publisher = "John Wiley and Sons, Inc.",
	address = "10475 Crosspoint Boulevard",
	edition = "1",
	year      = "2014",
}

@book{Learning_From_Data,
	title     = "Learning From Data",
	author    = "Yaser S. Abu-Mostafa, Malik Magdon-Ismail, Hsuan-Tien Lin",
	publisher = " ",
	address = "California Institute of Technology Pasadena, CA 91125, USA",
	edition = "1",
	year      = "2012",
}

@misc{SoftMax_MLM,
	title        = {Softmax Activation Function with Python},
	author       = {Jason Brownlee},
	year         = 2020,
	note         = {\url{https://machinelearningmastery.com/softmax-activation-function-with-python/} [Accessed:24/02/2024]}
}

@book{NN_From_Scratch,
	title     = "Neural Networks From Scratch in Python",
	author    = "Harrison Kinsley & Daniel Kukieła",
	publisher = " ",
	address = "Sentdex, Kinsley Enterprises Inc",
	edition = "1",
	year      = "2020",
}

@misc{ReLU,
	title        = {Unidad Lineal Rectificada},
	author       = {Douglas Karr },
	year         = 2024,
	note         = {\url{https://es.martech.zone/acronym/relu/} [Accessed:25/02/2024]}
}

@misc{Sigmoide,
	title        = {La Función Sigmoide: Una Herramienta Clave en Redes Neuronales},
	author       = {Javi},
	year         = 2023,
	note         = {\url{https://jacar.es/la-funcion-sigmoide-una-herramienta-clave-en-redes-neuronales/}  [Accessed:25/02/2024]}
}

@misc{SGD_1,
	title        = {Descenso del gradiente},
	author       = {},
	year         = 2024,
	note         = {\url{https://es.wikipedia.org/wiki/Descenso_del_gradiente#:~:text=El%20descenso%20del%20gradiente%20o,en%20direcci%C3%B3n%20contraria%20al%20gradiente.}  [Accessed:26/02/2024]}
}

@misc{SGD_2,
	title        = {Gradient Descent Algorithm — a deep dive},
	author       = {Robert Kwiatkowski},
	year         = 2021,
	note         = {\url{https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21#:~:text=Gradient%20descent%20(GD)%20is%20an,e.g.%20in%20a%20linear%20regression).}  [Accessed:26/02/2024]}
}

@misc{SGD_3,
	title        = {How is stochastic gradient descent implemented in the context of machine learning and deep learning?},
	author       = {Sebastian Raschka},
	year         = 2024,
	note         = {\url{https://sebastianraschka.com/faq/docs/sgd-methods.html}  [Accessed:27/03/2024]}
}

@misc{Gradiente,
	title        = {Gradiente},
	author       = {},
	year         = 2024,
	note         = {\url{https://es.wikipedia.org/wiki/Gradiente}  [Accessed:26/02/2024]}
}

@misc{SGD_act_params,
	title        = {How neural networks are trained},
	author       = {ml4a},
	year         =  2020,
	note         = {\url{https://ml4a.github.io/ml4a/how_neural_networks_are_trained/}  [Accessed:27/02/2024]}
}

@misc{Cross_entropy,
	title        = {What Is Cross Entropy Loss? A Tutorial With Code},
	author       = {Saurav Maheshkar},
	year         =  2023,
	note         = {\url{https://wandb.ai/sauravmaheshkar/cross-entropy/reports/What-Is-Cross-Entropy-Loss-A-Tutorial-With-Code--VmlldzoxMDA5NTMx#:~:text=Cross%20entropy%20loss%20is%20a,close%20to%200%20as%20possible.}  [Accessed:29/02/2024]}
}

@misc{Cross_entropy_backprop,
	title        = {Back-propagation through Cross-Entropy Softmax},
	author       = {mehran@mldawn.com},
	year         =  2021,
	note         = {\url{https://www.mldawn.com/back-propagation-with-cross-entropy-and-softmax/}  [Accessed:29/02/2024]}
}

@misc{Cross_entropy_backprop_grad_input,
	title        = {The derivative of softmax function wrt z},
	author       = {mehran@mldawn.com},
	year         =  2021,
	note         = {\url{https://www.mldawn.com/the-derivative-of-softmaxz-function-w-r-t-z/}  [Accessed:05/03/2024]}
}

@misc{NN_backpropagation,
	title        = {Back-Propagation is very simple. Who made it Complicated ?},
	author       = {Prakash Jay},
	year         =  2017,
	note         = {\url{https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c}  [Accessed:06/03/2024]}
}

@misc{NN_backprop_2,
	title        = {No more confusion on Backpropagation},
	author       = {Chamanth mvs},
	year         =  2022,
	note         = {\url{https://pub.aimind.so/no-more-confusion-on-backpropagation-7adfc271539f}  [Accessed:07/03/2024]}
}

@misc{ini_He,
	title        = {Weight Initialization for Deep Learning Neural Networks},
	author       = {Jason Brownlee},
	year         =  2021,
	note         = {\url{https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/}  [Accessed:14/03/2024]}
}

@misc{ini_He_2,
	title        = {Kaiming Initialization in Deep Learning},
	author       = {Sandeep Jain},
	year         =  2023,
	note         = {\url{https://www.geeksforgeeks.org/kaiming-initialization-in-deep-learning/ }  [Accessed:14/03/2024]}
}

@misc{ini_He_code,
	title        = {Understanding weight initialization for neural networks},
	author       = {Adrian Rosebrock},
	year         =  2021,
	note         = {\url{https://pyimagesearch.com/2021/05/06/understanding-weight-initialization-for-neural-networks/}  [Accessed:14/03/2024]}
}

@misc{ini_bias,
	title        = {Initial bias values for a neural network},
	author       = {Yahia Zakaria},
	year         =  2017,
	note         = {\url{https://stackoverflow.com/questions/44883861/initial-bias-values-for-a-neural-network}  [Accessed:14/03/2024]}
}

@misc{ini_bias_2,
	title        = {Bias Initialization in a Neural Network},
	author       = {Glen Meyerowitz},
	year         =  2018,
	note         = {\url{https://medium.com/@glenmeyerowitz/bias-initialization-in-a-neural-network-2e5d26fed0f0}  [Accessed:14/03/2024]}
}

@misc{capa_convolucional,
	title        = {Convolutional Neural Networks cheatsheet},
	author       = {Afshine Amidi y Shervine Amidi},
	year         =  2018,
	note         = {\url{https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks}  [Accessed:19/03/2024]}
}

@misc{capa_convolucional_Stanford,
	title        = {Convolutional Neural Networks (CNNs / ConvNets)},
	author       = {Stanford},
	year         =  2020,
	note         = {\url{https://cs231n.github.io/convolutional-networks/}  [Accessed:19/03/2024]}
}

@misc{sgd_stocastico,
	title        = {Stochastic gradient descent},
	author       = {Wikipedia},
	year         =  2024,
	note         = {\url{https://en.wikipedia.org/wiki/Stochastic_gradient_descent}  [Accessed:22/03/2024]}
}

@misc{sgd_stocastico_1,
	title        = {Stochastic Gradient Descent — Clearly Explained !!},
	author       = {
	Aishwarya V Srinivasan},
	year         =  2019,
	note         = {\url{https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31}  [Accessed:22/03/2024]}
}

@inproceedings{CNN_parallel_Stanford,
	title={Parallel and Distributed Deep Learning},
	author={Vishakh Hegde and Sheema Usmani},
	year={2016},
	url={https://api.semanticscholar.org/CorpusID:53135767}
}

@INPROCEEDINGS{CNN_parallel_International_Conference,
	author={Lee, Sunwoo and Jha, Dipendra and Agrawal, Ankit and Choudhary, Alok and Liao, Wei-keng},
	booktitle={2017 IEEE 24th International Conference on High Performance Computing (HiPC)}, 
	title={Parallel Deep Convolutional Neural Network Training by Exploiting the Overlapping of Computation and Communication}, 
	year={2017},
	volume={},
	number={},
	pages={183-192},
	keywords={Training;Computational modeling;Data models;Backpropagation;Neurons;Mathematical model;Convolution;Convolutional Neural Network;Deep Learning;Parallelization;Communication;Overlapping},
	doi={10.1109/HiPC.2017.00030}}

@article{CNN_parallel_Ome_Weird_Trick,
	title={One weird trick for parallelizing convolutional neural networks},
	author={Alex Krizhevsky},
	journal={ArXiv},
	year={2014},
	volume={abs/1404.5997},
	url={https://api.semanticscholar.org/CorpusID:5556470}
}

@misc{flatten_forward,
	title        = {Let’s Code Convolutional Neural Network in plain NumPy},
	author       = {Piotr Skalski},
	year         =  2020,
	note         = {\url{https://towardsdatascience.com/lets-code-convolutional-neural-network-in-plain-numpy-ce48e732f5d5}  [Accessed:24/03/2024]}
}

@misc{max_pool_backprop,
	title        = {Backprop Through Max-Pooling Layers?},
	author       = {Archana David},
	year         =  2007,
	note         = {\url{https://datascience.stackexchange.com/questions/11699/backprop-through-max-pooling-layers}  [Accessed:24/03/2024]}
}

@misc{max_pool_backprop_2,
	title        = {How to backpropagate through max-pooling layers},
	author       = {Muhammad Baqir},
	year         =  2024,
	note         = {\url{https://www.educative.io/answers/how-to-backpropagate-through-max-pooling-layers}  [Accessed:24/03/2024]}
}

@misc{conv_backprop,
	title        = {Calculate CNN backprop with padding and stride set to 2},
	author       = {Hide Inada},
	year         =  2024,
	note         = {\url{https://hideyukiinada.github.io/cnn_backprop_strides2.html}  [Accessed:01/04/2024]}
}

@misc{padding_1,
	title        = {CNN | Introduction to Padding},
	author       = {
	savyakhosla},
	year         =  2024,
	note         = {\url{https://www.geeksforgeeks.org/cnn-introduction-to-padding/}  [Accessed:02/04/2024]}
}

@inbook{padding_2,
	author = {Kumar, Avinash and Sarkar, Sobhangi and Pradhan, Chittaranjan},
	year = {2020},
	month = {01},
	pages = {211-230},
	title = {Malaria Disease Detection Using CNN Technique with SGD, RMSprop and ADAM Optimizers},
	isbn = {978-3-030-33965-4},
	doi = {10.1007/978-3-030-33966-1_11}
}

@article{conv_GEMM_FFT_comparacion,
	title={Performance Analysis of GPU-based Convolutional
	Neural Networks},
	author={Xiaqing Li†‡§, Guangyan Zhang†‡§, H. Howie Huang¶, Zhufan Wang†‡, Weimin Zheng†‡
	†Department of Computer Science and Technology, Tsinghua University
	‡Tsinghua National Laboratory for Information Science and Technology
	§State Key Lab of Mathematical Engineering and Advanced Computing, Wuxi, China
	¶Department of Electrical and Computer Engineering, George Washington University},
	journal={International Conference on Parallel Processing},
	year={2016},
	volume={ },
	url={https://www2.seas.gwu.edu/~howie/publications/GPU-CNN-ICPP16.pdf}
}

@misc{cuda_mult_matrix_v3,
	title        = {COMP 605: Introduction to Parallel Computing
	Lecture : CUDA Matrix-Matrix Multiplication},
	author       = {Mary Thomas},
	year         =  2017,
	note         = {\url{https://edoras.sdsu.edu/~mthomas/sp17.605/lectures/CUDA-Mat-Mat-Mult.pdf}  [Accessed:10/05/2024]}
}

@misc{nvidia_mult_matrix_v4,
	title        = {Matrix Multiplication Background,  User's Guide | NVIDIA Docs},
	author       = {NVIDIA},
	year         =  2023,
	note         = {\url{https://docs.nvidia.com/deeplearning/performance/pdf/Matrix-Multiplication-Background-User-Guide.pdf}  [Accessed:10/05/2024]}
}

@misc{nvidia_back_fully_GEMM,
	title        = {Linear/Fully-Connected Layers User's Guide},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html}  [Accessed:11/05/2024]}
}



@misc{importancia_ReLU,
	title        = {La importancia de las funciones de activación en una red neuronal},
	author       = {Jorge Calvo Martin},
	year         =  2022,
	note         = {\url{https://www.linkedin.com/pulse/la-importancia-de-las-funciones-activaci%C3%B3n-en-una-red-calvo-martin/}  [Accessed:10/06/2024]}
}



@misc{importancia_ReLU_2,
	title        = {La Función de Activación},
	author       = {Miguel Sotaquirá},
	year         =  2018,
	note         = {\url{https://www.codificandobits.com/blog/funcion-de-activacion/}  [Accessed:10/06/2024]}
}

@misc{cuDNN,
	title        = {NVIDIA cuDNN},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://developer.nvidia.com/cudnn}  [Accessed:02/08/2024]}
}

@misc{cuDNN_librerias,
	title        = {NVIDIA cuDNN},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://docs.nvidia.com/deeplearning/cudnn/latest/developer/overview.html#dev-overview}  [Accessed:02/08/2024]}
}

@misc{cuDNN_core_concepts,
	title        = {NVIDIA cuDNN},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://docs.nvidia.com/deeplearning/cudnn/latest/developer/core-concepts.html}  [Accessed:02/08/2024]}
}

@misc{cuDNN_conv_fwd,
	title        = {NVIDIA cuDNN},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://docs.nvidia.com/deeplearning/cudnn/latest/api/cudnn-cnn-library.html#cudnnconvolutionforward}  [Accessed:03/08/2024]}
}

@misc{cuDNN_pool_fwd,
	title        = {NVIDIA cuDNN},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-897/api/index.html#cudnnPoolingForward}  [Accessed:03/08/2024]}
}

@misc{cuDNN_conv_back_w,
	title        = {NVIDIA cuDNN},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://docs.nvidia.com/deeplearning/cudnn/latest/api/cudnn-cnn-library.html#cudnnconvolutionbackwardfilter}  [Accessed:03/08/2024]}
}

@misc{cuDNN_conv_back_x,
	title        = {NVIDIA cuDNN},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://docs.nvidia.com/deeplearning/cudnn/latest/api/cudnn-cnn-library.html#cudnnconvolutionbackwarddata}  [Accessed:03/08/2024]}
}

@misc{NN_intro,
	title        = {¿Qué son las redes neuronales?},
	author       = {IBM},
	year         =  2024,
	note         = {\url{https://www.ibm.com/es-es/topics/neural-networks#:~:text=%C2%BFQu%C3%A9%20son%20las%20redes%20neuronales,opciones%20y%20llegar%20a%20conclusiones.}  [Accessed:10/08/2024]}
}

@misc{funcion_activacion_definicion,
	title        = {Funciones de activación en Redes Neuronales},
	author       = {Sakshi Tiwari},
	year         =  2024,
	note         = {\url{https://www.geeksforgeeks.org/activation-functions-neural-networks/}  [Accessed:10/08/2024]}
}

@misc{openmp_forum,
	title        = {OpenMP},
	author       = {OpeMP},
	year         =  2024,
	note         = {\url{https://www.openmp.org/}  [Accessed:15/08/2024]}
}

@misc{cuda_forum,
	title        = {CUDA Toolkit},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://developer.nvidia.com/cuda-toolkit}  [Accessed:15/08/2024]}
}

@misc{CPU_definicion,
	title        = {¿Qué es una unidad central de procesamiento (CPU)?},
	author       = {Amazon},
	year         =  2024,
	note         = {\url{https://aws.amazon.com/es/what-is/cpu/}  [Accessed:15/08/2024]}
}

@misc{GPU_definicion,
	title        = {¿Qué es una GPU?},
	author       = {Amazon},
	year         =  2024,
	note         = {\url{https://aws.amazon.com/es/what-is/gpu/}  [Accessed:15/08/2024]}
}

@misc{CNN_definicion,
	title        = {What are convolutional neural networks?},
	author       = {IBM},
	year         =  2024,
	note         = {\url{https://www.ibm.com/topics/convolutional-neural-networks}  [Accessed:15/08/2024]}
}

@misc{Aprendizaje_automatico_definicion,
	title        = {¿Qué es el machine learning (ML)?},
	author       = {IBM},
	year         =  2024,
	note         = {\url{https://www.ibm.com/es-es/topics/machine-learning}  [Accessed:15/08/2024]}
}

@misc{Deep_learning_definicion,
	title        = {¿Qué es el deep learning?},
	author       = {IBM},
	year         =  2024,
	note         = {\url{https://www.ibm.com/es-es/topics/deep-learning}  [Accessed:15/08/2024]}
}

@misc{image_recognition_CNN,
	title        = {Image Classification Using CNN},
	author       = {Mohdsanadzakirizvi},
	year         =  2024,
	note         = {\url{https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/}  [Accessed:15/08/2024]}
}

@misc{computer_vision_definicion,
	title        = {¿Qué es la visión artificial?},
	author       = {Microsoft},
	year         =  2024,
	note         = {\url{https://azure.microsoft.com/es-es/resources/cloud-computing-dictionary/what-is-computer-vision#clasificaci%C3%B3n-de-objetos}  [Accessed:15/08/2024]}
}

@misc{object_detection_CNN,
	title        = {Overview of Object Detection Algorithms Using Convolutional Neural Networks},
	author       = {Jusong Ren, Yi Wang},
	year         =  2024,
	note         = {\url{https://www.scirp.org/journal/paperinformation?paperid=115011}  [Accessed:15/08/2024]}
}

@misc{image_segmentation_CNN,
	title        = {U-Net: Advancing Image Segmentation with Convolutional Neural Networks},
	author       = {Shameerayaseen},
	year         =  2023,
	note         = {\url{https://medium.com/@shameerayaseen21/u-net-advancing-image-segmentation-with-convolutional-neural-networks-1fd810f05d00}  [Accessed:15/08/2024]}
}

@misc{generative_CNN,
	title        = {Generative Modeling of Convolutional Neural Networks},
	author       = {Jifeng Dai, Yang Lu, Ying Nian Wu},
	year         =  2023,
	note         = {\url{http://www.stat.ucla.edu/~ywu/generativeCNN/main.html}  [Accessed:15/08/2024]}
}

@misc{video_analytics_CNN,
	title        = {Convolutional Neural Networks (CNNs), Deep Learning, and Computer Vision},
	author       = {Intel},
	year         =  2024,
	note         = {\url{https://www.intel.com/content/www/us/en/internet-of-things/computer-vision/convolutional-neural-networks.html}  [Accessed:15/08/2024]}
}

@misc{NLP_CNN,
	title        = {NLP with CNNs},
	author       = {Taha Binhuraib},
	year         =  2020,
	note         = {\url{https://towardsdatascience.com/nlp-with-cnns-a6aa743bdc1e}  [Accessed:15/08/2024]}
}

@misc{sitemas_autonomos_CNN,
	title        = {Convolutional Neural Networks (CNN) in Self-Driving Cars},
	author       = {Augmented AI},
	year         =  2024,
	note         = {\url{https://www.augmentedstartups.com/blog/convolutional-neural-networks-cnn-in-self-driving-cars#:~:text=They%20have%20the%20potential%20to,decisions%20based%20on%20the%20environment.}  [Accessed:15/08/2024]}
}

@misc{sitemas_heterogeneo_definicion,
	title        = {Heterogeneous systems},
	author       = {Patricio Bulić},
	year         =  2024,
	note         = {\url{https://doc.sling.si/en/workshops/programming-gpu-cuda/01-intro/02-hetsys/#:~:text=A%20homogeneous%20system%20uses%20one,%2Dsuited%2C%20yielding%20performance%20improvement.}  [Accessed:15/08/2024]}
}

@misc{Caffe2,
	title        = {What is Caffe2?},
	author       = {Caffe2},
	year         =  2024,
	note         = {\url{https://caffe2.ai/docs/caffe-migration.html}  [Accessed:15/08/2024]}
}

@misc{Keras,
	title        = {Keras},
	author       = {Keras},
	year         =  2024,
	note         = {\url{https://keras.io/}  [Accessed:15/08/2024]}
}

@misc{Matlab,
	title        = {Matlab},
	author       = {Mathworks},
	year         =  2024,
	note         = {\url{https://la.mathworks.com/products/matlab.html}  [Accessed:15/08/2024]}
}

@misc{Pytorch,
	title        = {Pytorch},
	author       = {Pytorch},
	year         =  2024,
	note         = {\url{https://pytorch.org/}  [Accessed:15/08/2024]}
}

@misc{Tensorflow,
	title        = {Tensorflow},
	author       = {Tensorflow},
	year         =  2024,
	note         = {\url{https://www.tensorflow.org/?hl=es-419}  [Accessed:15/08/2024]}
}

@misc{aprendizaje_supervisado,
	title        = {¿Qué es el aprendizaje supervisado?},
	author       = {IBM},
	year         =  2024,
	note         = {\url{https://www.ibm.com/es-es/topics/supervised-learning}  [Accessed:22/08/2024]}
}

@misc{etiquetas,
	title        = {¿Qué es el aprendizaje supervisado?},
	author       = {Interactive Chaos},
	year         =  2024,
	note         = {\url{https://interactivechaos.com/es/manual/tutorial-de-machine-learning/etiquetas}  [Accessed:22/08/2024]}
}

@misc{one_hot,
	title        = {One Hot Encoding},
	author       = {Interactive Chaos},
	year         =  2024,
	note         = {\url{https://interactivechaos.com/es/manual/tutorial-de-machine-learning/one-hot-encoding}  [Accessed:22/08/2024]}
}

@misc{padding_definicion,
	title        = {Understanding Padding in Machine Learning},
	author       = {DeepAI},
	year         =  2024,
	note         = {\url{https://deepai.org/machine-learning-glossary-and-terms/padding}  [Accessed:23/08/2024]}
}

@misc{full_padding_definicion,
	title        = {Full Padding},
	author       = {Avinash Kumar},
	year         =  2020,
	note         = {\url{https://www.researchgate.net/figure/Full-padding-and-same-padding-10_fig5_337287600}  [Accessed:23/08/2024]}
}

@misc{openmp_intro,
	title        = {What is OpenMP?},
	author       = {Arnab Chakraborty},
	year         =  2019,
	note         = {\url{https://www.tutorialspoint.com/what-is-openmp}  [Accessed:24/08/2024]}
}

@misc{cuda_kernels,
	title        = {CUDA C++ Programming Guide},
	author       = {NVIDIA},
	year         =  2024,
	note         = {\url{https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html}  [Accessed:24/08/2024]}
}

@misc{openmp_directivas,
	title        = {Directivas de OpenMP},
	author       = {Microsoft},
	year         =  2024,
	note         = {\url{https://learn.microsoft.com/es-es/cpp/parallel/openmp/reference/openmp-directives?view=msvc-170}  [Accessed:24/08/2024]}
}

@misc{data_model_parallelism,
	title        = {Data Parallelism VS Model Parallelism in Distributed Deep Learning Training},
	author       = {Lei Mao},
	year         =  2024,
	note         = {\url{https://leimao.github.io/blog/Data-Parallelism-vs-Model-Paralelism/}  [Accessed:25/08/2024]}
}

@misc{model_parallelism,
	title        = {What Is Model Parallelism?},
	author       = {PureStorage},
	year         =  2024,
	note         = {\url{https://www.purestorage.com/knowledge/what-is-model-parallelism.html}  [Accessed:25/08/2024]}
}


@misc{GEMM_definition,
	title        = {General Matrix Multiply (GeMM)},
	author       = {Stanford University},
	year         =  2018,
	note         = {\url{https://spatial-lang.org/gemm}  [Accessed:25/08/2024]}
}
