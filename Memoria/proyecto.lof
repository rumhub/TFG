\babel@toc {spanish}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Imagen de una neurona}}{7}{figure.caption.8}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Imagen de una capa de neuronas}}{7}{figure.caption.9}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Imagen de la función de activación ReLU}}{8}{figure.caption.11}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Imagen de la función de activación Sigmoide}}{9}{figure.caption.13}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Imagen de la función de activación SoftMax}}{9}{figure.caption.14}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Ejemplo de funcionamiento del descenso del gradiente}}{10}{figure.caption.16}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Componentes en una capa convolucional}}{13}{figure.caption.22}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Propagación hacia delante en una capa convolucional}}{14}{figure.caption.24}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Propagación hacia delante en una capa convolucional con varios canales de profundidad}}{15}{figure.caption.26}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Propagación hacia delante en una capa convolucional con varios filtros}}{16}{figure.caption.28}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Relleno sobre un volumen de entrada X}}{17}{figure.caption.30}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Relleno sobre un volumen de entrada X}}{17}{figure.caption.32}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Relleno sobre un volumen de entrada X}}{18}{figure.caption.33}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Componentes en una capa de agrupación máxima}}{19}{figure.caption.35}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces Propagación hacia delante en una capa de agrupación máxima}}{19}{figure.caption.37}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces Propagación hacia delante en una capa de agrupación máxima}}{20}{figure.caption.39}%
\contentsline {figure}{\numberline {2.16}{\ignorespaces Propagación hacia delante en una capa de agrupación máxima}}{20}{figure.caption.41}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Propagación hacia delante en una capa de agrupación máxima}}{22}{figure.caption.43}%
\contentsline {figure}{\numberline {2.18}{\ignorespaces Propagación hacia delante en una capa de agrupación máxima}}{23}{figure.caption.45}%
\contentsline {figure}{\numberline {2.19}{\ignorespaces Ejemplo de tensor 4D con dimensiones: N=1, C=1, H=5, y W=6}}{25}{figure.caption.49}%
\contentsline {figure}{\numberline {2.20}{\ignorespaces Ejemplo de tensor 4D NCHW con dimensiones: N=1, C=1, H=5, y W=6}}{26}{figure.caption.50}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Estructura de una red con softmax}}{33}{figure.caption.56}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Red Neuronal totalmente conectada con 1 capa oculta}}{36}{figure.caption.63}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Imagen de backpropagation en la capa softmax}}{37}{figure.caption.65}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Imagen de backpropagation en los pesos entre la capa oculta y la capa SoftMax}}{37}{figure.caption.67}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Imagen de los 'caminos' desde la capa softmax hasta $n^1_0$}}{38}{figure.caption.70}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Imagen de backpropagation en la capa oculta h1}}{39}{figure.caption.71}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Imagen de backpropagation en los pesos entre la capa input y la capa oculta h1}}{40}{figure.caption.73}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Imagen de los 'caminos' desde la capa oculta h1 hasta $n^0_0$}}{41}{figure.caption.76}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Imagen de backpropagation en la capa input}}{41}{figure.caption.77}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Red Neuronal totalmente conectada con 2 capas ocultas}}{42}{figure.caption.78}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Imagen de backpropagation en la capa softmax}}{42}{figure.caption.80}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Imagen de backpropagation en los pesos entre la capa oculta h2 y la capa SoftMax}}{43}{figure.caption.82}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Imagen de los 'caminos' desde la capa softmax hasta $n^2_0$}}{44}{figure.caption.85}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Imagen de backpropagation en la capa oculta h2}}{44}{figure.caption.86}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Imagen de backpropagation en los pesos entre las capas ocultas h1 y h2}}{45}{figure.caption.88}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces Imagen de los 'caminos' desde la capa softmax hasta $n^1_0$}}{46}{figure.caption.91}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces Imagen de backpropagation en la capa oculta h1}}{47}{figure.caption.92}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces Imagen de backpropagation en los pesos entre la capa input y la capa oculta h1}}{47}{figure.caption.94}%
\contentsline {figure}{\numberline {3.19}{\ignorespaces Imagen de los 'caminos' desde la capa oculta h1 hasta $n^0_0$}}{48}{figure.caption.97}%
\contentsline {figure}{\numberline {3.20}{\ignorespaces Imagen de backpropagation en la capa input}}{49}{figure.caption.98}%
\contentsline {figure}{\numberline {3.21}{\ignorespaces Imagen de backpropagation en la capa l}}{50}{figure.caption.100}%
\contentsline {figure}{\numberline {3.22}{\ignorespaces Imagen de backpropagation en los pesos entre la capa l-1 y l}}{50}{figure.caption.102}%
\contentsline {figure}{\numberline {3.23}{\ignorespaces Ejemplo de propagación hacia delante en una capa convolucional}}{53}{figure.caption.106}%
\contentsline {figure}{\numberline {3.24}{\ignorespaces Ejemplo de propagación hacia delante en una capa convolucional}}{54}{figure.caption.110}%
\contentsline {figure}{\numberline {3.25}{\ignorespaces Ejemplo de propagación hacia delante en una capa convolucional}}{55}{figure.caption.112}%
\contentsline {figure}{\numberline {3.26}{\ignorespaces Ejemplo de propagación hacia delante en una capa convolucional}}{56}{figure.caption.114}%
\contentsline {figure}{\numberline {3.27}{\ignorespaces Cálculo del gradiente de la pérdida respecto a cada filtro como convolución entre X e Y}}{58}{figure.caption.116}%
\contentsline {figure}{\numberline {3.28}{\ignorespaces Invertir pesos en K tanto horizontal como verticalmente}}{59}{figure.caption.118}%
\contentsline {figure}{\numberline {3.29}{\ignorespaces Cálculo del gradiente de la pérdida respecto a cada filtro como convolución entre X e Y}}{60}{figure.caption.119}%
\contentsline {figure}{\numberline {3.30}{\ignorespaces Ejemplo de propagación hacia detrás en una capa convolucional con relleno}}{61}{figure.caption.120}%
\contentsline {figure}{\numberline {3.31}{\ignorespaces Retropropagación de $Y^c_{11}$}}{61}{figure.caption.122}%
\contentsline {figure}{\numberline {3.32}{\ignorespaces Retropropagación de $Y^c_{12}$}}{62}{figure.caption.124}%
\contentsline {figure}{\numberline {3.33}{\ignorespaces Retropropagación de $Y^c_{13}$}}{63}{figure.caption.126}%
\contentsline {figure}{\numberline {3.34}{\ignorespaces Retropropagación de $Y^c_{21}$}}{63}{figure.caption.128}%
\contentsline {figure}{\numberline {3.35}{\ignorespaces Retropropagación de $Y^c_{22}$}}{64}{figure.caption.130}%
\contentsline {figure}{\numberline {3.36}{\ignorespaces Retropropagación de $Y^c_{23}$}}{65}{figure.caption.132}%
\contentsline {figure}{\numberline {3.37}{\ignorespaces Retropropagación de $Y^c_{31}$}}{66}{figure.caption.134}%
\contentsline {figure}{\numberline {3.38}{\ignorespaces Retropropagación de $Y^c_{32}$}}{66}{figure.caption.136}%
\contentsline {figure}{\numberline {3.39}{\ignorespaces Retropropagación de $Y^c_{33}$}}{67}{figure.caption.138}%
\contentsline {figure}{\numberline {3.40}{\ignorespaces Cálculo del gradiente de la pérdida respecto a cada filtro como convolución entre X e Y}}{68}{figure.caption.140}%
\contentsline {figure}{\numberline {3.41}{\ignorespaces Cálculo del gradiente de la pérdida respecto de la entrada como convolución}}{69}{figure.caption.142}%
\contentsline {figure}{\numberline {3.42}{\ignorespaces Cálculo del gradiente de la pérdida respecto a la entrada X con uno o dos niveles de relleno}}{70}{figure.caption.143}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Imagen de una convolución estándar frente a una convolución empleando GEMM}}{72}{figure.caption.144}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Retropropagación en una capa convolucional de forma estándar frente a GEMM respecto a la entrada}}{75}{figure.caption.145}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Retropropagación en una capa convolucional de forma estándar frente a GEMM respecto a los pesos}}{76}{figure.caption.146}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Propagación GEMM hacia delante en una capa totalmente conectada}}{77}{figure.caption.147}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Propagación GEMM de un minibatch entero hacia delante en una capa totalmente conectada}}{77}{figure.caption.148}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Cálculo del gradiente respecto a la entrada en una capa totalmente conectada}}{78}{figure.caption.150}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Cálculo del gradiente respecto a la entrada de todo un minibatch en una capa totalmente conectada}}{78}{figure.caption.151}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Cálculo del gradiente respecto a los pesos en una capa totalmente conectada}}{79}{figure.caption.153}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Cálculo del gradiente respecto a los pesos de todo un minibatch en una capa totalmente conectada}}{79}{figure.caption.154}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Tercera implementación de multiplicación matricial con CUDA}}{81}{figure.caption.155}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Cuarta implementación de multiplicación matricial con CUDA}}{82}{figure.caption.156}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Secuencial vs OpenMP}}{83}{figure.caption.157}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Ganancia de OpenMP respecto a secuencial}}{84}{figure.caption.158}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces OpenMP vs CUDA vs CUDNN}}{84}{figure.caption.159}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces CUDA vs CUDNN}}{85}{figure.caption.160}%
