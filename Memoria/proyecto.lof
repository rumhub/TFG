\babel@toc {spanish}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Esquema de una neurona}}{7}{figure.caption.7}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Esquema de una capa de neuronas}}{8}{figure.caption.8}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Imagen de la función de activación ReLU}}{9}{figure.caption.10}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Imagen de la función de activación Sigmoide}}{10}{figure.caption.12}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Imagen de la función de activación SoftMax}}{10}{figure.caption.13}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Ejemplo de funcionamiento del descenso del gradiente}}{13}{figure.caption.16}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Estructura de una red totalmente conectada con una capa oculta, y con softmax en la última capa}}{15}{figure.caption.19}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Retropropagación en la capa l}}{17}{figure.caption.21}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Retropropagación respecto a los pesos entre la capa l-1 y l}}{18}{figure.caption.23}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Esquema de las dimensiones en una capa convolucional de una red neuronal convolucional}}{19}{figure.caption.24}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Estructura por capas en una red neuronal convolucional}}{20}{figure.caption.25}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Componentes en una capa convolucional}}{21}{figure.caption.27}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Propagación hacia delante en una capa convolucional}}{22}{figure.caption.29}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces Propagación hacia delante en una capa convolucional con varios canales de profundidad}}{23}{figure.caption.31}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces Propagación hacia delante en una capa convolucional con varios filtros}}{24}{figure.caption.33}%
\contentsline {figure}{\numberline {2.16}{\ignorespaces Relleno sobre un volumen de entrada X}}{25}{figure.caption.35}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Relleno sobre un volumen de entrada X}}{25}{figure.caption.37}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Convolución sobre X con relleno completo}}{26}{figure.caption.38}%
\contentsline {figure}{\numberline {2.18}{\ignorespaces Ejemplo de propagación hacia delante en una capa convolucional}}{27}{figure.caption.39}%
\contentsline {figure}{\numberline {2.19}{\ignorespaces Cálculo del gradiente de la pérdida con respecto a cada filtro como convolución entre la entrada X y la salida Y}}{29}{figure.caption.43}%
\contentsline {figure}{\numberline {2.20}{\ignorespaces Inversión de los pesos en K tanto horizontal como verticalmente}}{30}{figure.caption.45}%
\contentsline {figure}{\numberline {2.21}{\ignorespaces Cálculo del gradiente de la pérdida con respecto a cada valor de entrada como convolución entre los pesos K y la salida Y}}{31}{figure.caption.46}%
\contentsline {figure}{\numberline {2.22}{\ignorespaces Cálculo del gradiente de la pérdida con respecto a la entrada X con uno y dos niveles de relleno}}{32}{figure.caption.47}%
\contentsline {figure}{\numberline {2.23}{\ignorespaces Componentes en una capa de agrupación máxima}}{33}{figure.caption.49}%
\contentsline {figure}{\numberline {2.24}{\ignorespaces Propagación hacia delante en una capa de agrupación máxima}}{33}{figure.caption.51}%
\contentsline {figure}{\numberline {2.25}{\ignorespaces Propagación hacia delante en una capa de agrupación máxima}}{34}{figure.caption.53}%
\contentsline {figure}{\numberline {2.26}{\ignorespaces Retropropagación en capa de agrupación máxima}}{34}{figure.caption.55}%
\contentsline {figure}{\numberline {2.27}{\ignorespaces Propagación hacia delante en una capa de aplanado}}{36}{figure.caption.57}%
\contentsline {figure}{\numberline {2.28}{\ignorespaces Retropropagación en una capa de aplanado}}{37}{figure.caption.59}%
\contentsline {figure}{\numberline {2.29}{\ignorespaces Jerarquía de hebras en un grid CUDA}}{39}{figure.caption.60}%
\contentsline {figure}{\numberline {2.30}{\ignorespaces Ejemplo de tensor 4D con dimensiones: N=1, C=1, H=5, y W=6}}{42}{figure.caption.64}%
\contentsline {figure}{\numberline {2.31}{\ignorespaces Ejemplo de tensor 4D NCHW con dimensiones: N=1, C=1, H=5, y W=6}}{42}{figure.caption.65}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Flujo de las hebras en la implementación con OpenMP}}{48}{figure.caption.74}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Convolución estándar frente a convolución GEMM}}{50}{figure.caption.75}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Retropropagación respecto a la entrada en una capa convolucional de forma estándar frente a GEMM}}{52}{figure.caption.76}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Retropropagación respecto a los pesos en una capa convolucional de forma estándar frente a GEMM}}{53}{figure.caption.77}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Propagación GEMM hacia delante en una capa totalmente conectada}}{54}{figure.caption.79}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Propagación GEMM de un minibatch entero hacia delante en una capa totalmente conectada}}{55}{figure.caption.80}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Cálculo del gradiente respecto a la entrada en una capa totalmente conectada}}{56}{figure.caption.83}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Cálculo del gradiente respecto a la entrada de todo un minibatch en una capa totalmente conectada}}{57}{figure.caption.84}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Cálculo del gradiente respecto a los pesos en una capa totalmente conectada}}{58}{figure.caption.86}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Cálculo del gradiente respecto a los pesos de todo un minibatch en una capa totalmente conectada}}{59}{figure.caption.87}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Tercera implementación de multiplicación matricial con CUDA}}{60}{figure.caption.88}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Cuarta implementación de multiplicación matricial con CUDA}}{61}{figure.caption.89}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Flujo de las hebras en la implementación con CUDA}}{62}{figure.caption.90}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Entrenamiento con CIFAR10}}{66}{figure.caption.91}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Entrenamiento con 10 Big Cats}}{67}{figure.caption.92}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Secuencial vs OpenMP}}{68}{figure.caption.94}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Ganancia de OpenMP respecto a secuencial}}{68}{figure.caption.95}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces OpenMP vs CUDA vs CUDNN}}{69}{figure.caption.97}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Ganancia de CUDA y cuDNN sobre OpenMP}}{70}{figure.caption.98}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces CUDA vs CUDNN}}{70}{figure.caption.99}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {C.1}{\ignorespaces Estructura de una red totalmente conectada con softmax en la última capa}}{87}{figure.caption.107}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {D.1}{\ignorespaces Red Neuronal totalmente conectada con 1 capa oculta}}{93}{figure.caption.108}%
\contentsline {figure}{\numberline {D.2}{\ignorespaces Retropropagación en la capa softmax}}{94}{figure.caption.109}%
\contentsline {figure}{\numberline {D.3}{\ignorespaces Retropropagación con respecto a pesos entre la capa oculta y la capa SoftMax}}{95}{figure.caption.110}%
\contentsline {figure}{\numberline {D.4}{\ignorespaces Imagen de los 'caminos' desde la capa softmax hasta la neurona $n^1_0$}}{96}{figure.caption.111}%
\contentsline {figure}{\numberline {D.5}{\ignorespaces Retropropagación con respecto a neuronas de la capa oculta h1}}{96}{figure.caption.112}%
\contentsline {figure}{\numberline {D.6}{\ignorespaces Retropropagación con respecto a los pesos entre la capa de entrada y la capa oculta h1}}{97}{figure.caption.113}%
\contentsline {figure}{\numberline {D.7}{\ignorespaces Imagen de los 'caminos' desde la capa oculta h1 hasta $n^0_0$}}{98}{figure.caption.114}%
\contentsline {figure}{\numberline {D.8}{\ignorespaces Retropropagación en la capa input}}{99}{figure.caption.115}%
\contentsline {figure}{\numberline {D.9}{\ignorespaces Red Neuronal totalmente conectada con 2 capas ocultas}}{100}{figure.caption.116}%
\contentsline {figure}{\numberline {D.10}{\ignorespaces Retropropagación en la capa softmax}}{100}{figure.caption.117}%
\contentsline {figure}{\numberline {D.11}{\ignorespaces Retropropagación respecto a los pesos entre la capa oculta h2 y la capa SoftMax}}{101}{figure.caption.118}%
\contentsline {figure}{\numberline {D.12}{\ignorespaces Imagen de los 'caminos' desde la capa softmax hasta $n^2_0$}}{102}{figure.caption.119}%
\contentsline {figure}{\numberline {D.13}{\ignorespaces Retropropagación en la capa oculta h2}}{102}{figure.caption.120}%
\contentsline {figure}{\numberline {D.14}{\ignorespaces Retropropagación respecto a los pesos entre las capas ocultas h1 y h2}}{103}{figure.caption.121}%
\contentsline {figure}{\numberline {D.15}{\ignorespaces 'Caminos' desde la capa softmax hasta $n^1_0$}}{104}{figure.caption.122}%
\contentsline {figure}{\numberline {D.16}{\ignorespaces Retropropagación en la capa oculta h1}}{105}{figure.caption.123}%
\contentsline {figure}{\numberline {D.17}{\ignorespaces Retropropagación respecto a los pesos entre la capa de entrada y la capa oculta h1}}{106}{figure.caption.124}%
\contentsline {figure}{\numberline {D.18}{\ignorespaces 'Caminos' desde la capa oculta h1 hasta $n^0_0$}}{107}{figure.caption.125}%
\contentsline {figure}{\numberline {D.19}{\ignorespaces Retropropagación en la capa input}}{107}{figure.caption.126}%
\contentsline {figure}{\numberline {D.20}{\ignorespaces Retropropagación en la capa l}}{108}{figure.caption.127}%
\contentsline {figure}{\numberline {D.21}{\ignorespaces Retropropagación respecto a los pesos entre la capa l-1 y l}}{109}{figure.caption.128}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {E.1}{\ignorespaces Ejemplo de propagación hacia delante en una capa convolucional}}{111}{figure.caption.129}%
\contentsline {figure}{\numberline {E.2}{\ignorespaces Cálculo de $Y^c_{12}$ mediante propagación hacia delante en una capa convolucional}}{113}{figure.caption.130}%
\contentsline {figure}{\numberline {E.3}{\ignorespaces Cálculo de $Y^c_{21}$ mediante propagación hacia delante en una capa convolucional}}{114}{figure.caption.131}%
\contentsline {figure}{\numberline {E.4}{\ignorespaces Cálculo de $Y^c_{22}$ mediante propagación hacia delante en una capa convolucional}}{115}{figure.caption.132}%
\contentsline {figure}{\numberline {E.5}{\ignorespaces Cálculo del gradiente de la pérdida con respecto a cada filtro como convolución entre X e Y}}{116}{figure.caption.133}%
\contentsline {figure}{\numberline {E.6}{\ignorespaces Inversión de los pesos en K tanto horizontal como verticalmente}}{117}{figure.caption.134}%
\contentsline {figure}{\numberline {E.7}{\ignorespaces Cálculo del gradiente de la pérdida con respecto a cada valor de entrada como convolución entre K e Y}}{118}{figure.caption.135}%
\contentsline {figure}{\numberline {E.8}{\ignorespaces Ejemplo de retropropagación en una capa convolucional con relleno}}{119}{figure.caption.136}%
\contentsline {figure}{\numberline {E.9}{\ignorespaces Retropropagación de $Y^c_{11}$}}{119}{figure.caption.137}%
\contentsline {figure}{\numberline {E.10}{\ignorespaces Retropropagación de $Y^c_{12}$}}{120}{figure.caption.138}%
\contentsline {figure}{\numberline {E.11}{\ignorespaces Retropropagación de $Y^c_{13}$}}{121}{figure.caption.139}%
\contentsline {figure}{\numberline {E.12}{\ignorespaces Retropropagación de $Y^c_{21}$}}{122}{figure.caption.140}%
\contentsline {figure}{\numberline {E.13}{\ignorespaces Retropropagación de $Y^c_{22}$}}{123}{figure.caption.141}%
\contentsline {figure}{\numberline {E.14}{\ignorespaces Retropropagación de $Y^c_{23}$}}{123}{figure.caption.142}%
\contentsline {figure}{\numberline {E.15}{\ignorespaces Retropropagación de $Y^c_{31}$}}{124}{figure.caption.143}%
\contentsline {figure}{\numberline {E.16}{\ignorespaces Retropropagación de $Y^c_{32}$}}{125}{figure.caption.144}%
\contentsline {figure}{\numberline {E.17}{\ignorespaces Retropropagación de $Y^c_{33}$}}{126}{figure.caption.145}%
\contentsline {figure}{\numberline {E.18}{\ignorespaces Cálculo del gradiente de la pérdida con respecto a cada filtro como convolución entre X e Y}}{127}{figure.caption.146}%
\contentsline {figure}{\numberline {E.19}{\ignorespaces Cálculo del gradiente de la pérdida con respecto a la entrada como convolución}}{128}{figure.caption.147}%
\contentsline {figure}{\numberline {E.20}{\ignorespaces Cálculo del gradiente de la pérdida con respecto a la entrada X con uno y dos niveles de relleno}}{129}{figure.caption.148}%
