\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\citation{Cross_entropy_backprop}
\citation{Cross_entropy_backprop_grad_input}
\citation{NN_backpropagation}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introducción}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Resumen}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Estado del arte}{1}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Objetivos}{1}{section.1.3}\protected@file@percent }
\citation{Programming_Massively}
\citation{Learning_From_Data}
\citation{Learning_From_Data}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Conceptos previos}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Machine Learning}{3}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Componentes necesarios para el aprendizaje supervisado}{3}{section.2.2}\protected@file@percent }
\citation{Learning_From_Data}
\citation{Learning_From_Data}
\citation{Learning_From_Data}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}División de datos en entrenamiento y test}{4}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Tipos de aprendizaje}{4}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Aprendizaje Supervisado}{4}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Aprendizaje No Supervisado}{4}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Aprendizaje Por Refuerzo}{4}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Redes Neuronales Totalmente Conectadas}{5}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Neurona}{5}{subsection.2.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Imagen de una neurona}}{5}{figure.2.1}\protected@file@percent }
\newlabel{fig:neurona}{{2.1}{5}{Imagen de una neurona}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Estructura por capas}{5}{subsection.2.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Imagen de una capa de neuronas}}{5}{figure.2.2}\protected@file@percent }
\newlabel{fig:capa_neuronas}{{2.2}{5}{Imagen de una capa de neuronas}{figure.2.2}{}}
\citation{ReLU}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Funciones de activación}{6}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{ReLU}{6}{section*.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Imagen de la función de activación ReLU}}{6}{figure.2.3}\protected@file@percent }
\newlabel{fig:ReLU}{{2.3}{6}{Imagen de la función de activación ReLU}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoide}{6}{section*.9}\protected@file@percent }
\citation{Sigmoide}
\citation{SoftMax_MLM}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Imagen de la función de activación Sigmoide}}{7}{figure.2.4}\protected@file@percent }
\newlabel{fig:Sigmoide}{{2.4}{7}{Imagen de la función de activación Sigmoide}{figure.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{SoftMax}{7}{section*.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Imagen de la función de activación SoftMax}}{7}{figure.2.5}\protected@file@percent }
\newlabel{fig:SoftMax}{{2.5}{7}{Imagen de la función de activación SoftMax}{figure.2.5}{}}
\citation{Cross_entropy}
\citation{SGD_1}
\citation{Gradiente}
\citation{SGD_2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}One-hot encoding}{8}{subsection.2.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.5}Función de error o pérdida}{8}{subsection.2.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Entropía Cruzada}{8}{section*.11}\protected@file@percent }
\newlabel{loss_func_softmax}{{2.3}{8}{Entropía Cruzada}{equation.2.5.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Cross Entropy Loss}{8}{section*.12}\protected@file@percent }
\newlabel{loss_func}{{2.4}{8}{Sigmoid Cross Entropy Loss}{equation.2.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.6}Descenso del gradiente}{8}{subsection.2.5.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Ejemplo de funcionamiento del descenso del gradiente}}{8}{figure.2.6}\protected@file@percent }
\newlabel{fig:SGD}{{2.6}{8}{Ejemplo de funcionamiento del descenso del gradiente}{figure.2.6}{}}
\citation{Cross_entropy}
\citation{SGD_act_params}
\@writefile{toc}{\contentsline {subsubsection}{Entrenamiento}{9}{section*.13}\protected@file@percent }
\newlabel{act_pesos}{{2.5}{9}{Entrenamiento}{equation.2.5.5}{}}
\newlabel{act_bias}{{2.6}{9}{Entrenamiento}{equation.2.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.7}Tipos de codificaciones}{9}{subsection.2.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.8}Propagación hacia delante con softmax}{9}{subsection.2.5.8}\protected@file@percent }
\citation{Cross_entropy_backprop}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Redes Neuronales Convolucionales}{10}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Tipos de capas}{10}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Estructura por capas}{10}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}ForwardPropagation}{10}{subsection.2.6.3}\protected@file@percent }
\citation{Cross_entropy_backprop}
\citation{Cross_entropy_backprop_grad_input}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Aportaciones}{11}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Redes Neuronales Totalmente Conectadas}{11}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Gradiente de la función de pérdida respecto a SoftMax, \cite  {Cross_entropy_backprop} \cite  {Cross_entropy_backprop_grad_input}}{11}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Estructura de una red con softmax}}{11}{figure.3.1}\protected@file@percent }
\newlabel{cross_entropy_notacion}{{3.1}{11}{Gradiente de la función de pérdida respecto a SoftMax, \cite {Cross_entropy_backprop} \cite {Cross_entropy_backprop_grad_input}}{equation.3.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Gradiente de la función de error}{11}{section*.14}\protected@file@percent }
\newlabel{gradiente_Oi_Zk}{{3.5}{12}{Gradiente de la función de error}{equation.3.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Derivada de softmax respecto de su entrada, $\frac  {\partial O_i}{\partial Z_k}$}{12}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Caso $\frac  {S(Z_i)}{Z_i}$}{12}{section*.16}\protected@file@percent }
\newlabel{grad_Oi_Zk_drch}{{3.13}{13}{Caso $\frac {S(Z_i)}{Z_i}$}{equation.3.1.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{Caso $\frac  {S(Z_i)}{Z_j}$, con i $\neq  $ j}{13}{section*.17}\protected@file@percent }
\newlabel{grad_Oi_Zk_izq}{{3.18}{13}{Caso $\frac {S(Z_i)}{Z_j}$, con i $\neq $ j}{equation.3.1.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{Combinación de casos}{13}{section*.18}\protected@file@percent }
\newlabel{simplificar}{{3.21}{13}{Combinación de casos}{equation.3.1.21}{}}
\citation{NN_backpropagation}
\@writefile{toc}{\contentsline {subsubsection}{Simplificación One-Hot}{14}{section*.19}\protected@file@percent }
\newlabel{one_hot_simplif}{{3.23}{14}{Simplificación One-Hot}{equation.3.1.23}{}}
\newlabel{gradiente_softmax}{{3.26}{14}{Simplificación One-Hot}{equation.3.1.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}BackPropagation con 1 capa oculta \cite  {NN_backpropagation}}{14}{subsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Red Neuronal totalmente conectada con 1 capa oculta}}{14}{figure.3.2}\protected@file@percent }
\newlabel{fig:nn_1_capa}{{3.2}{14}{Red Neuronal totalmente conectada con 1 capa oculta}{figure.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Capa SoftMax}{15}{section*.20}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Imagen de backpropagation en la capa softmax}}{15}{figure.3.3}\protected@file@percent }
\newlabel{fig:nn_1_capa_output}{{3.3}{15}{Imagen de backpropagation en la capa softmax}{figure.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pesos capas h1-SoftMax}{15}{section*.21}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Imagen de backpropagation en los pesos entre la capa oculta y la capa SoftMax}}{15}{figure.3.4}\protected@file@percent }
\newlabel{fig:nn_1_pesos_h1_output}{{3.4}{15}{Imagen de backpropagation en los pesos entre la capa oculta y la capa SoftMax}{figure.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Capa oculta h1}{16}{section*.22}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Imagen de los 'caminos' desde la capa softmax hasta $n^1_0$}}{16}{figure.3.5}\protected@file@percent }
\newlabel{nn_caminos_posibles}{{3.5}{16}{Imagen de los 'caminos' desde la capa softmax hasta $n^1_0$}{figure.3.5}{}}
\newlabel{E_total_a1p}{{3.29}{16}{Capa oculta h1}{equation.3.1.29}{}}
\newlabel{deriv_Zk_z1p}{{3.30}{16}{Capa oculta h1}{equation.3.1.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Imagen de backpropagation en la capa oculta h1}}{16}{figure.3.6}\protected@file@percent }
\newlabel{fig:nn_1_capa_h1}{{3.6}{16}{Imagen de backpropagation en la capa oculta h1}{figure.3.6}{}}
\newlabel{deriv_z1p_a1p}{{3.33}{17}{Capa oculta h1}{equation.3.1.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pesos capas input-h1}{17}{section*.23}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Imagen de backpropagation en los pesos entre la capa input y la capa oculta h1}}{17}{figure.3.7}\protected@file@percent }
\newlabel{fig:nn_1_pesos_input_h1}{{3.7}{17}{Imagen de backpropagation en los pesos entre la capa input y la capa oculta h1}{figure.3.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Capa input}{18}{section*.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Imagen de los 'caminos' desde la capa oculta h1 hasta $n^0_0$}}{18}{figure.3.8}\protected@file@percent }
\newlabel{nn_caminos_posibles_input}{{3.8}{18}{Imagen de los 'caminos' desde la capa oculta h1 hasta $n^0_0$}{figure.3.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Imagen de backpropagation en la capa input}}{18}{figure.3.9}\protected@file@percent }
\newlabel{fig:nn_1_capa_input}{{3.9}{18}{Imagen de backpropagation en la capa input}{figure.3.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Adaptación GPU}{19}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}GPU en Redes Neuronales Totalmente Conectadas}{19}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}GPU en Redes Neuronales Convolucionales}{19}{section.4.2}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{bibliografia/bibliografia}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Comparación con distintas plataformas}{21}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}cuDNN}{21}{section.5.1}\protected@file@percent }
\bibcite{Cross_entropy_backprop}{1}
\bibcite{Cross_entropy_backprop_grad_input}{2}
\bibcite{Programming_Massively}{3}
\bibcite{Learning_From_Data}{4}
\bibcite{ReLU}{5}
\bibcite{Sigmoide}{6}
\bibcite{SoftMax_MLM}{7}
\bibcite{Cross_entropy}{8}
\bibcite{SGD_1}{9}
\bibcite{Gradiente}{10}
\bibcite{SGD_2}{11}
\bibcite{SGD_act_params}{12}
\bibcite{NN_backpropagation}{13}
\gdef \@abspage@last{47}
